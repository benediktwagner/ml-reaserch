{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# About Logic Tensor Network (LTN)\n",
    "This notebook decomposes and investigates an LTN library in order to understand its building blocks.<br>\n",
    "This is work in progress.\n",
    "\n",
    "This video explains the tutorials https://www.youtube.com/watch?v=KhkCjCmK8m0 (in second half)<br>\n",
    "`Rights to be wrong reserved`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "LTN imported from:  C:\\Projects\\ml-reaserch\\logictensornetworks\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "# path to LTN to include in system paths\n",
    "path = 'C:\\\\Users\\\\Greg\\\\Documents\\\\Projects\\\\LTN'\n",
    "sys.path.append(path)\n",
    "\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import logictensornetworks as ltn\n",
    "from logictensornetworks import utils_ltn\n",
    "import numpy as np\n",
    "# import utils_ltn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "print('LTN imported from: ', os.path.dirname(ltn.__file__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "LAYERS = 4\n",
    "BIAS_factor = 0.0\n",
    "BIAS = 0.0\n",
    "\n",
    "# Global placeholders for logical symbols\n",
    "F_And = None\n",
    "F_Or = None\n",
    "F_Implies = None\n",
    "F_Equiv = None\n",
    "F_Not = None\n",
    "F_Forall = None\n",
    "F_Exists = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Norms\n",
    "This is a hyper-parametr that defines how logical operators are calculated, with the following options:\n",
    "- min\n",
    "- Lukasiewicz\n",
    "- product\n",
    "- mean\n",
    "\n",
    "wff, wffs = \"well formated formula/s\". Formulas are build using groundings in Real vectors.<br> \n",
    "(examples to add).\n",
    "The norms are used in Fuzzy Sets Theory.<br>\n",
    "Some videos and readings on this matters:\n",
    "- https://www.youtube.com/watch?v=oWqXwCEfY78\n",
    "- https://www.youtube.com/watch?v=a2i-lHS-c_I\n",
    "- ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from the ltn library\n",
    "def set_tnorm(tnorm):\n",
    "    assert tnorm in ['min','luk','prod','mean','']\n",
    "    global F_And,F_Or,F_Implies,F_Not,F_Equiv,F_Forall\n",
    "    if tnorm == \"min\":\n",
    "        def F_And(wffs):\n",
    "            return tf.reduce_min(wffs,axis=-1,keepdims=True)\n",
    "\n",
    "        def F_Or(wffs):\n",
    "            return tf.reduce_max(wffs,axis=-1,keepdims=True)\n",
    "\n",
    "        def F_Implies(wff1, wff2):\n",
    "            return tf.maximum(tf.to_float(tf.less_equal(wff1,wff2)),wff2)\n",
    "\n",
    "        def F_Not(wff):\n",
    "            return 1 - wff\n",
    "\n",
    "        def F_Equiv(wff1,wff2):\n",
    "            return tf.maximum(tf.to_float(tf.equal(wff1,wff2)),tf.minimum(wff1,wff2))\n",
    "\n",
    "    if tnorm == \"prod\":\n",
    "        def F_And(wffs):\n",
    "            return tf.reduce_prod(wffs,axis=-1,keepdims=True)\n",
    "\n",
    "        def F_Or(wffs):\n",
    "            return 1-tf.reduce_prod(1-wffs,axis=-1,keepdims=True)\n",
    "\n",
    "        def F_Implies(wff1, wff2):\n",
    "            le_wff1_wff2 = tf.to_float(tf.less_equal(wff1,wff2))\n",
    "            gt_wff1_wff2 = tf.to_float(tf.greater(wff1,wff2))\n",
    "            return tf.cond(tf.equal(wff1[0],0),lambda:le_wff1_wff2 + gt_wff1_wff2*wff2/wff1,lambda:tf.constant([1.0]))\n",
    "\n",
    "        def F_Not(wff):\n",
    "            # according to standard goedel logic is\n",
    "            # return tf.to_float(tf.equal(wff,1))\n",
    "            return 1-wff\n",
    "\n",
    "        def F_Equiv(wff1,wff2):\n",
    "            return tf.minimum(wff1/wff2,wff2/wff1)\n",
    "\n",
    "    if tnorm == \"mean\":\n",
    "        def F_And(wffs):\n",
    "            return tf.reduce_mean(wffs,axis=-1,keepdims=True)\n",
    "\n",
    "        def F_Or(wffs):\n",
    "            return tf.reduce_max(wffs,axis=-1,keepdims=True)\n",
    "\n",
    "        def F_Implies(wff1, wff2):\n",
    "            return tf.clip_by_value(2*wff2-wff1,0,1)\n",
    "\n",
    "        def F_Not(wff):\n",
    "            return 1 - wff\n",
    "\n",
    "        def F_Equiv(wff1,wff2):\n",
    "            return 1 - tf.abs(wff1-wff2)\n",
    "\n",
    "    if tnorm == \"luk\":\n",
    "        def F_And(wffs):\n",
    "            return tf.maximum(0.0,tf.reduce_sum(wffs,axis=-1,keepdims=True)+1-tf.to_float(tf.shape(wffs)[-1]))\n",
    "\n",
    "        def F_Or(wffs):\n",
    "            return tf.minimum(tf.reduce_sum(wffs,axis=-1,keepdims=True),1.0,)\n",
    "\n",
    "        def F_Implies(wff1, wff2):\n",
    "            return tf.minimum(1.,1 - wff1 + wff2)\n",
    "\n",
    "        def F_Not(wff):\n",
    "            return 1 - wff\n",
    "\n",
    "        def F_Equiv(wff1,wff2):\n",
    "            return 1 - tf.abs(wff1-wff2)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `draw_ltn_operators` in `utils_ltn.py` has been created to visualise either unary or binary operators.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.5 0.1]\n",
      " [0.2 0.3]\n",
      " [0.6 0.2]\n",
      " [0.2 0.4]\n",
      " [0.3 0.6]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set a desired norm\n",
    "ltn.set_tnorm(\"min\")\n",
    "\n",
    "# some data \n",
    "data = np.array([[0.5, 0.2, 0.6, 0.2, 0.3], \n",
    "                 [0.1, 0.3, 0.2, 0.4, 0.6]], dtype=np.float32)\n",
    "\n",
    "labels = ['d_'+str(i+1) for i in np.arange(len(data[0]))]\n",
    "\n",
    "formulas = tf.placeholder(dtype=tf.float32)\n",
    "\n",
    "\n",
    "data_a, data_b = data[0], data[1] \n",
    "\n",
    "a = ltn.variable('a', data_a)\n",
    "b = ltn.variable('a', data_b)\n",
    "\n",
    "op = ltn.F_Or\n",
    "if op == ltn.F_And or op == ltn.F_Or:\n",
    "    with tf.Session() as sess:\n",
    "        data_in = np.stack(data, axis=1)\n",
    "        c = sess.run(op(formulas), feed_dict={formulas: data_in}) \n",
    "        data_c = np.array(utils_ltn.flat_list(c))\n",
    "        print(data_in)\n",
    "        utils_ltn.draw_ltn_operators(a=data_a, b=data_b, c=data_c, title=op, labels=labels)\n",
    "\n",
    "elif op == ltn.F_Implies or op == ltn.F_Equiv:\n",
    "    with tf.Session() as sess:\n",
    "        c = sess.run(op(a, b), feed_dict={a:data_a, b:data_b})\n",
    "        data_c = np.array(c)\n",
    "        utils_ltn.draw_ltn_operators(a=data_a, b=data_b, c=data_c, title=op, labels=labels)\n",
    "    \n",
    "elif op == ltn.F_Not:\n",
    "    with tf.Session() as sess:\n",
    "        c = sess.run(op(a), feed_dict={a:data_a})\n",
    "        data_c = np.array(c)\n",
    "        utils_ltn.draw_ltn_operators(a=data_a, c=data_c, title=op, labels=labels)\n",
    "else: 'Not implemented'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_universal_aggreg(aggreg):\n",
    "    assert aggreg in ['hmean','min','mean']\n",
    "    global F_Forall\n",
    "    if aggreg == \"hmean\":\n",
    "        def F_Forall(axis,wff):\n",
    "            return 1/tf.reduce_mean(1/(wff+1e-10),axis=axis)\n",
    "\n",
    "    if aggreg == \"min\":\n",
    "        def F_Forall(axis,wff):\n",
    "            return tf.reduce_min(wff,axis=axis)\n",
    "\n",
    "    if aggreg == \"mean\":\n",
    "        def F_Forall(axis,wff):\n",
    "            return tf.reduce_mean(wff, axis=axis)\n",
    "\n",
    "\n",
    "def set_existential_aggregator(aggreg):\n",
    "    assert  aggreg in ['max']\n",
    "    global F_Exists\n",
    "    if aggreg == \"max\":\n",
    "        def F_Exists(axis, wff):\n",
    "            return tf.reduce_max(wff, axis=axis)\n",
    "        \n",
    "set_universal_aggreg(\"hmean\")\n",
    "set_existential_aggregator(\"max\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function logictensornetworks.Or>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ltn.Or()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "............"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To be continued piece by piece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Or(*wffs):\n",
    "    if len(wffs) == 0:\n",
    "        result = tf.constant(0.0)\n",
    "        result.doms = []\n",
    "    else:\n",
    "        cross_wffs,_ = cross_args(wffs)\n",
    "        label = \"_OR_\".join([wff.name.split(\":\")[0] for wff in wffs])\n",
    "        result = tf.identity(F_Or(cross_wffs),name=label)\n",
    "        result.doms = cross_wffs.doms\n",
    "    return result\n",
    "\n",
    "\n",
    "def And(*wffs):\n",
    "    if len(wffs) == 0:\n",
    "        result = tf.constant(1.0)\n",
    "        result.doms = []\n",
    "    else:\n",
    "        cross_wffs,_ = cross_args(wffs)\n",
    "        label = \"_AND_\".join([wff.name.split(\":\")[0] for wff in wffs])\n",
    "        result = tf.identity(F_And(cross_wffs),name=label)\n",
    "        result.doms = cross_wffs.doms\n",
    "    return result\n",
    "\n",
    "\n",
    "#def Or(*wffs):\n",
    "#    if len(wffs) == 0:\n",
    " #       result = tf.constant(0.0)\n",
    "#        result.doms = []\n",
    "#    else:\n",
    "#        cross_wffs,_ = cross_args(wffs)\n",
    " #       label = \"_OR_\".join([wff.name.split(\":\")[0] for wff in wffs])\n",
    "  #      result = tf.identity(F_Or(cross_wffs),name=label)\n",
    " #       result.doms = cross_wffs.doms\n",
    "#    return result\n",
    "\n",
    "\n",
    "def Implies(wff1, wff2):\n",
    "    _, cross_wffs = cross_2args(wff1,wff2)\n",
    "    label = wff1.name.split(\":\")[0] + \"_IMP_\" + wff2.name.split(\":\")[0]\n",
    "    result = F_Implies(cross_wffs[0],cross_wffs[1])\n",
    "    result = tf.identity(result,name=label)\n",
    "    result.doms = cross_wffs[0].doms\n",
    "    return result\n",
    "\n",
    "def Not(wff):\n",
    "    result = F_Not(wff)\n",
    "    label = \"NOT_\" + wff.name.split(\":\")[0]\n",
    "    result = tf.identity(result,name=label)\n",
    "    result.doms = wff.doms\n",
    "    return result\n",
    "\n",
    "def Equiv(wff1,wff2):\n",
    "    _, cross_wffs = cross_2args(wff1,wff2)\n",
    "    label = wff1.name.split(\":\")[0] + \"_IFF_\" + wff2.name.split(\":\")[0]\n",
    "    result = F_Equiv(cross_wffs[0],cross_wffs[1])\n",
    "    result.doms = cross_wffs[0].doms\n",
    "    return result\n",
    "\n",
    "def Forall(vars,wff):\n",
    "    if type(vars) is not tuple:\n",
    "        vars = (vars,)\n",
    "    result_doms = [x for x in wff.doms if x not in [var.doms[0] for var in vars]]\n",
    "    quantif_axis = [wff.doms.index(var.doms[0]) for var in vars]\n",
    "    not_empty_vars = tf.cast(tf.reduce_prod(tf.stack([tf.size(var) for var in vars])),tf.bool)\n",
    "    ones = tf.ones((1,)*(len(result_doms)+1))\n",
    "    result = tf.cond(not_empty_vars,lambda:F_Forall(quantif_axis,wff),lambda:ones)\n",
    "    result.doms = result_doms\n",
    "    return result\n",
    "\n",
    "def Exists(vars,wff):\n",
    "    if type(vars) is not tuple:\n",
    "        vars = (vars,)\n",
    "    result_doms = [x for x in wff.doms if x not in [var.doms[0] for var in vars]]\n",
    "    quantif_axis = [wff.doms.index(var.doms[0]) for var in vars]\n",
    "    not_empty_vars = tf.cast(tf.reduce_prod(tf.stack([tf.size(var) for var in vars])),tf.bool)\n",
    "    zeros = tf.zeros((1,)*(len(result_doms)+1))\n",
    "    result = tf.cond(not_empty_vars,lambda:F_Exists(quantif_axis,wff),lambda:zeros)\n",
    "    result.doms = result_doms\n",
    "    return result\n",
    "\n",
    "# tf.cast\n",
    "# tf.stack VS np.stack\n",
    "# tf.size\n",
    "\n",
    "\n",
    "def variable(label,number_of_features_or_feed):\n",
    "    if type(number_of_features_or_feed) is int:\n",
    "        result = tf.placeholder(dtype=tf.float32,shape=(None,number_of_features_or_feed),name=label)\n",
    "    elif isinstance(number_of_features_or_feed,tf.Tensor):\n",
    "        result = tf.identity(number_of_features_or_feed,name=label)\n",
    "    else:\n",
    "        result = tf.constant(number_of_features_or_feed,name=label)\n",
    "    result.doms = [label]\n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def constant(label,value=None,\n",
    "                 min_value=None,\n",
    "                 max_value=None):\n",
    "    label = \"ltn_constant_\"+label\n",
    "    if value is not None:\n",
    "        result = tf.constant(value,name=label)\n",
    "    else:\n",
    "        result = tf.Variable(tf.random_uniform(\n",
    "                shape=(1,len(min_value)),\n",
    "                minval=min_value,\n",
    "                maxval=max_value,name=label))\n",
    "    result.doms = []\n",
    "    return result\n",
    "\n",
    "def function(label, input_shape_spec, output_shape_spec=1,fun_definition=None):\n",
    "    if type(input_shape_spec) is list:\n",
    "        number_of_features = sum([int(v.shape[1]) for v in input_shape_spec])\n",
    "    elif type(input_shape_spec) is tf.Tensor:\n",
    "        number_of_features = int(input_shape_spec.shape[1])\n",
    "    else:\n",
    "        number_of_features = input_shape_spec\n",
    "    if fun_definition is None:\n",
    "        W = tf.Variable(\n",
    "                tf.random_normal(\n",
    "                    [number_of_features + 1,output_shape_spec],mean=0,stddev=1), name=\"W\" + label)\n",
    "        def apply_fun(*args):\n",
    "            tensor_args = tf.concat(args,axis=1)\n",
    "            X = tf.concat([tf.ones((tf.shape(tensor_args)[0], 1)),\n",
    "                           tensor_args], 1)\n",
    "            result = tf.matmul(X,W)\n",
    "            return result\n",
    "        pars = [W]\n",
    "    else:\n",
    "        def apply_fun(*args):\n",
    "            return fun_definition(*args)\n",
    "        pars = []\n",
    "\n",
    "    def fun(*args):\n",
    "        crossed_args, list_of_args_in_crossed_args = cross_args(args)\n",
    "        result = apply_fun(*list_of_args_in_crossed_args)\n",
    "        if crossed_args.doms != []:\n",
    "            result = tf.reshape(result, tf.concat([tf.shape(crossed_args)[:-1],\n",
    "                                                   tf.shape(result)[-1:]],axis=0))\n",
    "        else:\n",
    "            result = tf.reshape(result, (output_shape_spec,))\n",
    "        result.doms = crossed_args.doms\n",
    "        return result\n",
    "    fun.pars = pars\n",
    "    fun.label=label\n",
    "    return fun\n",
    "\n",
    "def proposition(label,initial_value=None,value=None):\n",
    "    if value is not None:\n",
    "        assert 0 <= value and value <= 1\n",
    "        result = tf.constant([value])\n",
    "    elif initial_value is not None:\n",
    "        assert 0 <= initial_value <= 1\n",
    "        result = tf.Variable(initial_value=[value])\n",
    "    else:\n",
    "        result = tf.expand_dims(tf.clip_by_value(tf.Variable(tf.random_normal(shape=(),mean=.5,stddev=.5)),0.,1.),dim=0)\n",
    "    result.doms = ()\n",
    "    return result\n",
    "\n",
    "def predicate(label,number_of_features_or_vars,pred_definition=None):\n",
    "    global BIAS\n",
    "    if type(number_of_features_or_vars) is list:\n",
    "        number_of_features = sum([int(v.shape[1]) for v in number_of_features_or_vars])\n",
    "    elif type(number_of_features_or_vars) is tf.Tensor:\n",
    "        number_of_features = int(number_of_features_or_vars.shape[1])\n",
    "    else:\n",
    "        number_of_features = number_of_features_or_vars\n",
    "    if pred_definition is None:\n",
    "        W = tf.matrix_band_part(\n",
    "            tf.Variable(\n",
    "                tf.random_normal(\n",
    "                    [LAYERS,\n",
    "                     number_of_features + 1,\n",
    "                     number_of_features + 1],mean=0,stddev=1), name=\"W\" + label), 0, -1)\n",
    "        u = tf.Variable(tf.ones([LAYERS, 1]),\n",
    "                        name=\"u\" + label)\n",
    "        def apply_pred(*args):\n",
    "            app_label = label + \"/\" + \"_\".join([arg.name.split(\":\")[0] for arg in args]) + \"/\"\n",
    "            tensor_args = tf.concat(args,axis=1)\n",
    "            X = tf.concat([tf.ones((tf.shape(tensor_args)[0], 1)),\n",
    "                           tensor_args], 1)\n",
    "            XW = tf.matmul(tf.tile(tf.expand_dims(X, 0), [LAYERS, 1, 1]), W)\n",
    "            XWX = tf.squeeze(tf.matmul(tf.expand_dims(X, 1), tf.transpose(XW, [1, 2, 0])), axis=[1])\n",
    "            gX = tf.matmul(tf.tanh(XWX), u)\n",
    "            result = tf.sigmoid(gX, name=app_label)\n",
    "            return result\n",
    "        pars = [W,u]\n",
    "    else:\n",
    "        def apply_pred(*args):\n",
    "            return pred_definition(*args)\n",
    "        pars = []\n",
    "\n",
    "    def pred(*args):\n",
    "        global BIAS\n",
    "        crossed_args, list_of_args_in_crossed_args = cross_args(args)\n",
    "        result = apply_pred(*list_of_args_in_crossed_args)\n",
    "        if crossed_args.doms != []:\n",
    "            result = tf.reshape(result, tf.concat([tf.shape(crossed_args)[:-1],[1]],axis=0))\n",
    "        else:\n",
    "            result = tf.reshape(result, (1,))\n",
    "        result.doms = crossed_args.doms\n",
    "        BIAS = tf.divide(BIAS + .5 - tf.reduce_mean(result),2)*BIAS_factor\n",
    "        return result\n",
    "    pred.pars = pars\n",
    "    pred.label=label\n",
    "    return pred\n",
    "\n",
    "def cross_args(args):\n",
    "    result = args[0]\n",
    "    for arg in args[1:]:\n",
    "        result,_ = cross_2args(result,arg)\n",
    "    result_flat = tf.reshape(result,\n",
    "                             (tf.reduce_prod(tf.shape(result)[:-1]),\n",
    "                              tf.shape(result)[-1]))\n",
    "    result_args = tf.split(result_flat,[tf.shape(arg)[-1] for arg in args],1)\n",
    "    return result, result_args\n",
    "\n",
    "def cross_2args(X,Y):\n",
    "    if X.doms == [] and Y.doms == []:\n",
    "        result = tf.concat([X,Y],axis=-1)\n",
    "        result.doms = []\n",
    "        return result,[X,Y]\n",
    "    X_Y = set(X.doms) - set(Y.doms)\n",
    "    Y_X = set(Y.doms) - set(X.doms)\n",
    "    eX = X\n",
    "    eX_doms = [x for x in X.doms]\n",
    "    for y in Y_X:\n",
    "        eX = tf.expand_dims(eX,0)\n",
    "        eX_doms.append(y)\n",
    "    eY = Y\n",
    "    eY_doms = [y for y in Y.doms]\n",
    "    for x in X_Y:\n",
    "        eY = tf.expand_dims(eY,0)\n",
    "        eY_doms.append(x)\n",
    "    perm_eY = []\n",
    "    for y in eY_doms:\n",
    "        perm_eY.append(eX_doms.index(y))\n",
    "    eY = tf.transpose(eY,perm_eY + [len(perm_eY)])\n",
    "    mult_eX = [1]*(len(eX_doms)+1)\n",
    "    mult_eY = [1]*(len(eY_doms)+1)\n",
    "    for i in range(len(mult_eX)-1):\n",
    "        mult_eX[i] = tf.maximum(1,tf.floor_div(tf.shape(eY)[i],tf.shape(eX)[i]))\n",
    "        mult_eY[i] = tf.maximum(1,tf.floor_div(tf.shape(eX)[i],tf.shape(eY)[i]))\n",
    "    result1 = tf.tile(eX,mult_eX)\n",
    "    result2 = tf.tile(eY,mult_eY)\n",
    "    result = tf.concat([result1,result2],axis=-1)\n",
    "    result1.doms = eX_doms\n",
    "    result2.doms = eX_doms\n",
    "    result.doms = eX_doms\n",
    "    return result,[result1,result2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_2args(X,Y):\n",
    "    if X.doms == [] and Y.doms == []:\n",
    "        result = tf.concat([X,Y],axis=-1)\n",
    "        result.doms = []\n",
    "        return result,[X,Y]\n",
    "    X_Y = set(X.doms) - set(Y.doms)\n",
    "    Y_X = set(Y.doms) - set(X.doms)\n",
    "    eX = X\n",
    "    eX_doms = [x for x in X.doms]\n",
    "    for y in Y_X:\n",
    "        eX = tf.expand_dims(eX,0)\n",
    "        eX_doms.append(y)\n",
    "    eY = Y\n",
    "    eY_doms = [y for y in Y.doms]\n",
    "    for x in X_Y:\n",
    "        eY = tf.expand_dims(eY,0)\n",
    "        eY_doms.append(x)\n",
    "    perm_eY = []\n",
    "    for y in eY_doms:\n",
    "        perm_eY.append(eX_doms.index(y))\n",
    "    eY = tf.transpose(eY,perm_eY + [len(perm_eY)])\n",
    "    mult_eX = [1]*(len(eX_doms)+1)\n",
    "    mult_eY = [1]*(len(eY_doms)+1)\n",
    "    for i in range(len(mult_eX)-1):\n",
    "        mult_eX[i] = tf.maximum(1,tf.floor_div(tf.shape(eY)[i],tf.shape(eX)[i]))\n",
    "        mult_eY[i] = tf.maximum(1,tf.floor_div(tf.shape(eX)[i],tf.shape(eY)[i]))\n",
    "    result1 = tf.tile(eX,mult_eX)\n",
    "    result2 = tf.tile(eY,mult_eY)\n",
    "    result = tf.concat([result1,result2],axis=-1)\n",
    "    result1.doms = eX_doms\n",
    "    result2.doms = eX_doms\n",
    "    result.doms = eX_doms\n",
    "    return result,[result1,result2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result, [result1,result2] = cross_2args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'a_6_2:0' shape=<unknown> dtype=float32>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ltn.And(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Or' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-0638c176d9ba>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0msess\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mdata_in\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0ml\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mOr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mc_data\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'Or' is not defined"
     ]
    }
   ],
   "source": [
    "c = tf.placeholder(tf.float32)\n",
    "sess = tf.Session()\n",
    "data_in = np.stack(data, axis=1)\n",
    "l = sess.run(Or(c), feed_dict={c:c_data})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'And' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-be900875da37>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mAnd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mdata_c\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mltn_draw_logicals\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata_a\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata_b\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata_c\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'And' is not defined"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    c = sess.run(And(a)); \n",
    "    data_c = np.array(c)\n",
    "    utils.ltn_draw_logicals(a=data_a, b=data_b, c=data_c, title=op, labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
