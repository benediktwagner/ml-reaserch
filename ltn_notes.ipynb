{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "# About Logic Tensor Network (LTN)\n",
        "This notebook decomposes and investigates an LTN library in order to understand its building blocks.\u003cbr\u003e\n",
        "This is work in progress.\n",
        "\n",
        "This video explains the tutorials https://www.youtube.com/watch?v\u003dKhkCjCmK8m0 (in second half)\u003cbr\u003e\n",
        "`Rights to be wrong reserved`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LTN imported from:  C:\\Projects\\ml-reaserch\n"
          ]
        }
      ],
      "source": "import sys\n# path to LTN to include in system paths\npath \u003d \u0027C:\\\\Users\\\\Greg\\\\Documents\\\\Projects\\\\LTN\u0027\nsys.path.append(path)\n\nimport os\nimport tensorflow as tf\nimport logictensornetworks as ltn\nimport numpy as np\nfrom logictensornetworks import utils_ltn\nimport matplotlib.pyplot as plt\n\n%load_ext autoreload\n%autoreload 2\n%matplotlib inline\nprint(\u0027LTN imported from: \u0027, os.path.dirname(ltn.__file__))"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [],
      "source": [
        "LAYERS \u003d 4\n",
        "BIAS_factor \u003d 0.0\n",
        "BIAS \u003d 0.0\n",
        "\n",
        "# Global placeholders for logical symbols\n",
        "F_And \u003d None\n",
        "F_Or \u003d None\n",
        "F_Implies \u003d None\n",
        "F_Equiv \u003d None\n",
        "F_Not \u003d None\n",
        "F_Forall \u003d None\n",
        "F_Exists \u003d None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "## Setting Norms\n",
        "This is a hyper-parametr that defines how logical operators are calculated, with the following options:\n",
        "- min\n",
        "- Lukasiewicz\n",
        "- product\n",
        "- mean\n",
        "\n",
        "wff, wffs \u003d \"well formated formula/s\". Formulas are build using groundings in Real vectors.\u003cbr\u003e \n",
        "(examples to add).\n",
        "The norms are used in Fuzzy Sets Theory.\u003cbr\u003e\n",
        "Some videos and readings on this matters:\n",
        "- https://www.youtube.com/watch?v\u003doWqXwCEfY78\n",
        "- https://www.youtube.com/watch?v\u003da2i-lHS-c_I\n",
        "- ...\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [],
      "source": [
        "# from the ltn library\n",
        "def set_tnorm(tnorm):\n",
        "    assert tnorm in [\u0027min\u0027,\u0027luk\u0027,\u0027prod\u0027,\u0027mean\u0027,\u0027\u0027]\n",
        "    global F_And,F_Or,F_Implies,F_Not,F_Equiv,F_Forall\n",
        "    if tnorm \u003d\u003d \"min\":\n",
        "        def F_And(wffs):\n",
        "            return tf.reduce_min(wffs,axis\u003d-1,keepdims\u003dTrue)\n",
        "\n",
        "        def F_Or(wffs):\n",
        "            return tf.reduce_max(wffs,axis\u003d-1,keepdims\u003dTrue)\n",
        "\n",
        "        def F_Implies(wff1, wff2):\n",
        "            return tf.maximum(tf.to_float(tf.less_equal(wff1,wff2)),wff2)\n",
        "\n",
        "        def F_Not(wff):\n",
        "            return 1 - wff\n",
        "\n",
        "        def F_Equiv(wff1,wff2):\n",
        "            return tf.maximum(tf.to_float(tf.equal(wff1,wff2)),tf.minimum(wff1,wff2))\n",
        "\n",
        "    if tnorm \u003d\u003d \"prod\":\n",
        "        def F_And(wffs):\n",
        "            return tf.reduce_prod(wffs,axis\u003d-1,keepdims\u003dTrue)\n",
        "\n",
        "        def F_Or(wffs):\n",
        "            return 1-tf.reduce_prod(1-wffs,axis\u003d-1,keepdims\u003dTrue)\n",
        "\n",
        "        def F_Implies(wff1, wff2):\n",
        "            le_wff1_wff2 \u003d tf.to_float(tf.less_equal(wff1,wff2))\n",
        "            gt_wff1_wff2 \u003d tf.to_float(tf.greater(wff1,wff2))\n",
        "            return tf.cond(tf.equal(wff1[0],0),lambda:le_wff1_wff2 + gt_wff1_wff2*wff2/wff1,lambda:tf.constant([1.0]))\n",
        "\n",
        "        def F_Not(wff):\n",
        "            # according to standard goedel logic is\n",
        "            # return tf.to_float(tf.equal(wff,1))\n",
        "            return 1-wff\n",
        "\n",
        "        def F_Equiv(wff1,wff2):\n",
        "            return tf.minimum(wff1/wff2,wff2/wff1)\n",
        "\n",
        "    if tnorm \u003d\u003d \"mean\":\n",
        "        def F_And(wffs):\n",
        "            return tf.reduce_mean(wffs,axis\u003d-1,keepdims\u003dTrue)\n",
        "\n",
        "        def F_Or(wffs):\n",
        "            return tf.reduce_max(wffs,axis\u003d-1,keepdims\u003dTrue)\n",
        "\n",
        "        def F_Implies(wff1, wff2):\n",
        "            return tf.clip_by_value(2*wff2-wff1,0,1)\n",
        "\n",
        "        def F_Not(wff):\n",
        "            return 1 - wff\n",
        "\n",
        "        def F_Equiv(wff1,wff2):\n",
        "            return 1 - tf.abs(wff1-wff2)\n",
        "\n",
        "    if tnorm \u003d\u003d \"luk\":\n",
        "        def F_And(wffs):\n",
        "            return tf.maximum(0.0,tf.reduce_sum(wffs,axis\u003d-1,keepdims\u003dTrue)+1-tf.to_float(tf.shape(wffs)[-1]))\n",
        "\n",
        "        def F_Or(wffs):\n",
        "            return tf.minimum(tf.reduce_sum(wffs,axis\u003d-1,keepdims\u003dTrue),1.0,)\n",
        "\n",
        "        def F_Implies(wff1, wff2):\n",
        "            return tf.minimum(1.,1 - wff1 + wff2)\n",
        "\n",
        "        def F_Not(wff):\n",
        "            return 1 - wff\n",
        "\n",
        "        def F_Equiv(wff1,wff2):\n",
        "            return 1 - tf.abs(wff1-wff2)\n",
        "        \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "The function `draw_ltn_operators` in `utils_ltn.py` has been created to visualise either unary or binary operators.\u003cbr\u003e"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[0.5 0.1]\n",
            " [0.2 0.3]\n",
            " [0.6 0.2]\n",
            " [0.2 0.4]\n",
            " [0.3 0.6]]\n"
          ]
        },
        {
          "data": {
            "image/png": "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\u003d\n",
            "text/plain": [
              "\u003cFigure size 432x288 with 1 Axes\u003e"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Set a desired norm\n",
        "ltn.set_tnorm(\"min\")\n",
        "\n",
        "# some data \n",
        "data \u003d np.array([[0.5, 0.2, 0.6, 0.2, 0.3], \n",
        "                 [0.1, 0.3, 0.2, 0.4, 0.6]], dtype\u003dnp.float32)\n",
        "\n",
        "labels \u003d [\u0027d_\u0027+str(i+1) for i in np.arange(len(data[0]))]\n",
        "\n",
        "formulas \u003d tf.placeholder(dtype\u003dtf.float32)\n",
        "\n",
        "\n",
        "data_a, data_b \u003d data[0], data[1] \n",
        "\n",
        "a \u003d ltn.variable(\u0027a\u0027, data_a)\n",
        "b \u003d ltn.variable(\u0027a\u0027, data_b)\n",
        "\n",
        "op \u003d ltn.F_Or\n",
        "if op \u003d\u003d ltn.F_And or op \u003d\u003d ltn.F_Or:\n",
        "    with tf.Session() as sess:\n",
        "        data_in \u003d np.stack(data, axis\u003d1)\n",
        "        c \u003d sess.run(op(formulas), feed_dict\u003d{formulas: data_in}) \n",
        "        data_c \u003d np.array(utils_ltn.flat_list(c))\n",
        "        print(data_in)\n",
        "        utils_ltn.draw_ltn_operators(a\u003ddata_a, b\u003ddata_b, c\u003ddata_c, title\u003dop, labels\u003dlabels)\n",
        "\n",
        "elif op \u003d\u003d ltn.F_Implies or op \u003d\u003d ltn.F_Equiv:\n",
        "    with tf.Session() as sess:\n",
        "        c \u003d sess.run(op(a, b), feed_dict\u003d{a:data_a, b:data_b})\n",
        "        data_c \u003d np.array(c)\n",
        "        utils_ltn.draw_ltn_operators(a\u003ddata_a, b\u003ddata_b, c\u003ddata_c, title\u003dop, labels\u003dlabels)\n",
        "    \n",
        "elif op \u003d\u003d ltn.F_Not:\n",
        "    with tf.Session() as sess:\n",
        "        c \u003d sess.run(op(a), feed_dict\u003d{a:data_a})\n",
        "        data_c \u003d np.array(c)\n",
        "        utils_ltn.draw_ltn_operators(a\u003ddata_a, c\u003ddata_c, title\u003dop, labels\u003dlabels)\n",
        "else: \u0027Not implemented\u0027"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [],
      "source": [
        "def set_universal_aggreg(aggreg):\n",
        "    assert aggreg in [\u0027hmean\u0027,\u0027min\u0027,\u0027mean\u0027]\n",
        "    global F_Forall\n",
        "    if aggreg \u003d\u003d \"hmean\":\n",
        "        def F_Forall(axis,wff):\n",
        "            return 1/tf.reduce_mean(1/(wff+1e-10),axis\u003daxis)\n",
        "\n",
        "    if aggreg \u003d\u003d \"min\":\n",
        "        def F_Forall(axis,wff):\n",
        "            return tf.reduce_min(wff,axis\u003daxis)\n",
        "\n",
        "    if aggreg \u003d\u003d \"mean\":\n",
        "        def F_Forall(axis,wff):\n",
        "            return tf.reduce_mean(wff, axis\u003daxis)\n",
        "\n",
        "\n",
        "def set_existential_aggregator(aggreg):\n",
        "    assert  aggreg in [\u0027max\u0027]\n",
        "    global F_Exists\n",
        "    if aggreg \u003d\u003d \"max\":\n",
        "        def F_Exists(axis, wff):\n",
        "            return tf.reduce_max(wff, axis\u003daxis)\n",
        "        \n",
        "set_universal_aggreg(\"hmean\")\n",
        "set_existential_aggregator(\"max\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\u003ctf.Tensor \u0027Const:0\u0027 shape\u003d() dtype\u003dfloat32\u003e"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ltn.Or()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "............"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "# To be continued piece by piece"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [],
      "source": [
        "def Or(*wffs):\n",
        "    if len(wffs) \u003d\u003d 0:\n",
        "        result \u003d tf.constant(0.0)\n",
        "        result.doms \u003d []\n",
        "    else:\n",
        "        cross_wffs,_ \u003d cross_args(wffs)\n",
        "        label \u003d \"_OR_\".join([wff.name.split(\":\")[0] for wff in wffs])\n",
        "        result \u003d tf.identity(F_Or(cross_wffs),name\u003dlabel)\n",
        "        result.doms \u003d cross_wffs.doms\n",
        "    return result\n",
        "\n",
        "\n",
        "def And(*wffs):\n",
        "    if len(wffs) \u003d\u003d 0:\n",
        "        result \u003d tf.constant(1.0)\n",
        "        result.doms \u003d []\n",
        "    else:\n",
        "        cross_wffs,_ \u003d cross_args(wffs)\n",
        "        label \u003d \"_AND_\".join([wff.name.split(\":\")[0] for wff in wffs])\n",
        "        result \u003d tf.identity(F_And(cross_wffs),name\u003dlabel)\n",
        "        result.doms \u003d cross_wffs.doms\n",
        "    return result\n",
        "\n",
        "\n",
        "#def Or(*wffs):\n",
        "#    if len(wffs) \u003d\u003d 0:\n",
        " #       result \u003d tf.constant(0.0)\n",
        "#        result.doms \u003d []\n",
        "#    else:\n",
        "#        cross_wffs,_ \u003d cross_args(wffs)\n",
        " #       label \u003d \"_OR_\".join([wff.name.split(\":\")[0] for wff in wffs])\n",
        "  #      result \u003d tf.identity(F_Or(cross_wffs),name\u003dlabel)\n",
        " #       result.doms \u003d cross_wffs.doms\n",
        "#    return result\n",
        "\n",
        "\n",
        "def Implies(wff1, wff2):\n",
        "    _, cross_wffs \u003d cross_2args(wff1,wff2)\n",
        "    label \u003d wff1.name.split(\":\")[0] + \"_IMP_\" + wff2.name.split(\":\")[0]\n",
        "    result \u003d F_Implies(cross_wffs[0],cross_wffs[1])\n",
        "    result \u003d tf.identity(result,name\u003dlabel)\n",
        "    result.doms \u003d cross_wffs[0].doms\n",
        "    return result\n",
        "\n",
        "def Not(wff):\n",
        "    result \u003d F_Not(wff)\n",
        "    label \u003d \"NOT_\" + wff.name.split(\":\")[0]\n",
        "    result \u003d tf.identity(result,name\u003dlabel)\n",
        "    result.doms \u003d wff.doms\n",
        "    return result\n",
        "\n",
        "def Equiv(wff1,wff2):\n",
        "    _, cross_wffs \u003d cross_2args(wff1,wff2)\n",
        "    label \u003d wff1.name.split(\":\")[0] + \"_IFF_\" + wff2.name.split(\":\")[0]\n",
        "    result \u003d F_Equiv(cross_wffs[0],cross_wffs[1])\n",
        "    result.doms \u003d cross_wffs[0].doms\n",
        "    return result\n",
        "\n",
        "def Forall(vars,wff):\n",
        "    if type(vars) is not tuple:\n",
        "        vars \u003d (vars,)\n",
        "    result_doms \u003d [x for x in wff.doms if x not in [var.doms[0] for var in vars]]\n",
        "    quantif_axis \u003d [wff.doms.index(var.doms[0]) for var in vars]\n",
        "    not_empty_vars \u003d tf.cast(tf.reduce_prod(tf.stack([tf.size(var) for var in vars])),tf.bool)\n",
        "    ones \u003d tf.ones((1,)*(len(result_doms)+1))\n",
        "    result \u003d tf.cond(not_empty_vars,lambda:F_Forall(quantif_axis,wff),lambda:ones)\n",
        "    result.doms \u003d result_doms\n",
        "    return result\n",
        "\n",
        "def Exists(vars,wff):\n",
        "    if type(vars) is not tuple:\n",
        "        vars \u003d (vars,)\n",
        "    result_doms \u003d [x for x in wff.doms if x not in [var.doms[0] for var in vars]]\n",
        "    quantif_axis \u003d [wff.doms.index(var.doms[0]) for var in vars]\n",
        "    not_empty_vars \u003d tf.cast(tf.reduce_prod(tf.stack([tf.size(var) for var in vars])),tf.bool)\n",
        "    zeros \u003d tf.zeros((1,)*(len(result_doms)+1))\n",
        "    result \u003d tf.cond(not_empty_vars,lambda:F_Exists(quantif_axis,wff),lambda:zeros)\n",
        "    result.doms \u003d result_doms\n",
        "    return result\n",
        "\n",
        "# tf.cast\n",
        "# tf.stack VS np.stack\n",
        "# tf.size\n",
        "\n",
        "\n",
        "def variable(label,number_of_features_or_feed):\n",
        "    if type(number_of_features_or_feed) is int:\n",
        "        result \u003d tf.placeholder(dtype\u003dtf.float32,shape\u003d(None,number_of_features_or_feed),name\u003dlabel)\n",
        "    elif isinstance(number_of_features_or_feed,tf.Tensor):\n",
        "        result \u003d tf.identity(number_of_features_or_feed,name\u003dlabel)\n",
        "    else:\n",
        "        result \u003d tf.constant(number_of_features_or_feed,name\u003dlabel)\n",
        "    result.doms \u003d [label]\n",
        "    return result\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def constant(label,value\u003dNone,\n",
        "                 min_value\u003dNone,\n",
        "                 max_value\u003dNone):\n",
        "    label \u003d \"ltn_constant_\"+label\n",
        "    if value is not None:\n",
        "        result \u003d tf.constant(value,name\u003dlabel)\n",
        "    else:\n",
        "        result \u003d tf.Variable(tf.random_uniform(\n",
        "                shape\u003d(1,len(min_value)),\n",
        "                minval\u003dmin_value,\n",
        "                maxval\u003dmax_value,name\u003dlabel))\n",
        "    result.doms \u003d []\n",
        "    return result\n",
        "\n",
        "def function(label, input_shape_spec, output_shape_spec\u003d1,fun_definition\u003dNone):\n",
        "    if type(input_shape_spec) is list:\n",
        "        number_of_features \u003d sum([int(v.shape[1]) for v in input_shape_spec])\n",
        "    elif type(input_shape_spec) is tf.Tensor:\n",
        "        number_of_features \u003d int(input_shape_spec.shape[1])\n",
        "    else:\n",
        "        number_of_features \u003d input_shape_spec\n",
        "    if fun_definition is None:\n",
        "        W \u003d tf.Variable(\n",
        "                tf.random_normal(\n",
        "                    [number_of_features + 1,output_shape_spec],mean\u003d0,stddev\u003d1), name\u003d\"W\" + label)\n",
        "        def apply_fun(*args):\n",
        "            tensor_args \u003d tf.concat(args,axis\u003d1)\n",
        "            X \u003d tf.concat([tf.ones((tf.shape(tensor_args)[0], 1)),\n",
        "                           tensor_args], 1)\n",
        "            result \u003d tf.matmul(X,W)\n",
        "            return result\n",
        "        pars \u003d [W]\n",
        "    else:\n",
        "        def apply_fun(*args):\n",
        "            return fun_definition(*args)\n",
        "        pars \u003d []\n",
        "\n",
        "    def fun(*args):\n",
        "        crossed_args, list_of_args_in_crossed_args \u003d cross_args(args)\n",
        "        result \u003d apply_fun(*list_of_args_in_crossed_args)\n",
        "        if crossed_args.doms !\u003d []:\n",
        "            result \u003d tf.reshape(result, tf.concat([tf.shape(crossed_args)[:-1],\n",
        "                                                   tf.shape(result)[-1:]],axis\u003d0))\n",
        "        else:\n",
        "            result \u003d tf.reshape(result, (output_shape_spec,))\n",
        "        result.doms \u003d crossed_args.doms\n",
        "        return result\n",
        "    fun.pars \u003d pars\n",
        "    fun.label\u003dlabel\n",
        "    return fun\n",
        "\n",
        "def proposition(label,initial_value\u003dNone,value\u003dNone):\n",
        "    if value is not None:\n",
        "        assert 0 \u003c\u003d value and value \u003c\u003d 1\n",
        "        result \u003d tf.constant([value])\n",
        "    elif initial_value is not None:\n",
        "        assert 0 \u003c\u003d initial_value \u003c\u003d 1\n",
        "        result \u003d tf.Variable(initial_value\u003d[value])\n",
        "    else:\n",
        "        result \u003d tf.expand_dims(tf.clip_by_value(tf.Variable(tf.random_normal(shape\u003d(),mean\u003d.5,stddev\u003d.5)),0.,1.),dim\u003d0)\n",
        "    result.doms \u003d ()\n",
        "    return result\n",
        "\n",
        "def predicate(label,number_of_features_or_vars,pred_definition\u003dNone):\n",
        "    global BIAS\n",
        "    if type(number_of_features_or_vars) is list:\n",
        "        number_of_features \u003d sum([int(v.shape[1]) for v in number_of_features_or_vars])\n",
        "    elif type(number_of_features_or_vars) is tf.Tensor:\n",
        "        number_of_features \u003d int(number_of_features_or_vars.shape[1])\n",
        "    else:\n",
        "        number_of_features \u003d number_of_features_or_vars\n",
        "    if pred_definition is None:\n",
        "        W \u003d tf.matrix_band_part(\n",
        "            tf.Variable(\n",
        "                tf.random_normal(\n",
        "                    [LAYERS,\n",
        "                     number_of_features + 1,\n",
        "                     number_of_features + 1],mean\u003d0,stddev\u003d1), name\u003d\"W\" + label), 0, -1)\n",
        "        u \u003d tf.Variable(tf.ones([LAYERS, 1]),\n",
        "                        name\u003d\"u\" + label)\n",
        "        def apply_pred(*args):\n",
        "            app_label \u003d label + \"/\" + \"_\".join([arg.name.split(\":\")[0] for arg in args]) + \"/\"\n",
        "            tensor_args \u003d tf.concat(args,axis\u003d1)\n",
        "            X \u003d tf.concat([tf.ones((tf.shape(tensor_args)[0], 1)),\n",
        "                           tensor_args], 1)\n",
        "            XW \u003d tf.matmul(tf.tile(tf.expand_dims(X, 0), [LAYERS, 1, 1]), W)\n",
        "            XWX \u003d tf.squeeze(tf.matmul(tf.expand_dims(X, 1), tf.transpose(XW, [1, 2, 0])), axis\u003d[1])\n",
        "            gX \u003d tf.matmul(tf.tanh(XWX), u)\n",
        "            result \u003d tf.sigmoid(gX, name\u003dapp_label)\n",
        "            return result\n",
        "        pars \u003d [W,u]\n",
        "    else:\n",
        "        def apply_pred(*args):\n",
        "            return pred_definition(*args)\n",
        "        pars \u003d []\n",
        "\n",
        "    def pred(*args):\n",
        "        global BIAS\n",
        "        crossed_args, list_of_args_in_crossed_args \u003d cross_args(args)\n",
        "        result \u003d apply_pred(*list_of_args_in_crossed_args)\n",
        "        if crossed_args.doms !\u003d []:\n",
        "            result \u003d tf.reshape(result, tf.concat([tf.shape(crossed_args)[:-1],[1]],axis\u003d0))\n",
        "        else:\n",
        "            result \u003d tf.reshape(result, (1,))\n",
        "        result.doms \u003d crossed_args.doms\n",
        "        BIAS \u003d tf.divide(BIAS + .5 - tf.reduce_mean(result),2)*BIAS_factor\n",
        "        return result\n",
        "    pred.pars \u003d pars\n",
        "    pred.label\u003dlabel\n",
        "    return pred\n",
        "\n",
        "def cross_args(args):\n",
        "    result \u003d args[0]\n",
        "    for arg in args[1:]:\n",
        "        result,_ \u003d cross_2args(result,arg)\n",
        "    result_flat \u003d tf.reshape(result,\n",
        "                             (tf.reduce_prod(tf.shape(result)[:-1]),\n",
        "                              tf.shape(result)[-1]))\n",
        "    result_args \u003d tf.split(result_flat,[tf.shape(arg)[-1] for arg in args],1)\n",
        "    return result, result_args\n",
        "\n",
        "def cross_2args(X,Y):\n",
        "    if X.doms \u003d\u003d [] and Y.doms \u003d\u003d []:\n",
        "        result \u003d tf.concat([X,Y],axis\u003d-1)\n",
        "        result.doms \u003d []\n",
        "        return result,[X,Y]\n",
        "    X_Y \u003d set(X.doms) - set(Y.doms)\n",
        "    Y_X \u003d set(Y.doms) - set(X.doms)\n",
        "    eX \u003d X\n",
        "    eX_doms \u003d [x for x in X.doms]\n",
        "    for y in Y_X:\n",
        "        eX \u003d tf.expand_dims(eX,0)\n",
        "        eX_doms.append(y)\n",
        "    eY \u003d Y\n",
        "    eY_doms \u003d [y for y in Y.doms]\n",
        "    for x in X_Y:\n",
        "        eY \u003d tf.expand_dims(eY,0)\n",
        "        eY_doms.append(x)\n",
        "    perm_eY \u003d []\n",
        "    for y in eY_doms:\n",
        "        perm_eY.append(eX_doms.index(y))\n",
        "    eY \u003d tf.transpose(eY,perm_eY + [len(perm_eY)])\n",
        "    mult_eX \u003d [1]*(len(eX_doms)+1)\n",
        "    mult_eY \u003d [1]*(len(eY_doms)+1)\n",
        "    for i in range(len(mult_eX)-1):\n",
        "        mult_eX[i] \u003d tf.maximum(1,tf.floor_div(tf.shape(eY)[i],tf.shape(eX)[i]))\n",
        "        mult_eY[i] \u003d tf.maximum(1,tf.floor_div(tf.shape(eX)[i],tf.shape(eY)[i]))\n",
        "    result1 \u003d tf.tile(eX,mult_eX)\n",
        "    result2 \u003d tf.tile(eY,mult_eY)\n",
        "    result \u003d tf.concat([result1,result2],axis\u003d-1)\n",
        "    result1.doms \u003d eX_doms\n",
        "    result2.doms \u003d eX_doms\n",
        "    result.doms \u003d eX_doms\n",
        "    return result,[result1,result2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [],
      "source": [
        "def cross_2args(X,Y):\n",
        "    if X.doms \u003d\u003d [] and Y.doms \u003d\u003d []:\n",
        "        result \u003d tf.concat([X,Y],axis\u003d-1)\n",
        "        result.doms \u003d []\n",
        "        return result,[X,Y]\n",
        "    X_Y \u003d set(X.doms) - set(Y.doms)\n",
        "    Y_X \u003d set(Y.doms) - set(X.doms)\n",
        "    eX \u003d X\n",
        "    eX_doms \u003d [x for x in X.doms]\n",
        "    for y in Y_X:\n",
        "        eX \u003d tf.expand_dims(eX,0)\n",
        "        eX_doms.append(y)\n",
        "    eY \u003d Y\n",
        "    eY_doms \u003d [y for y in Y.doms]\n",
        "    for x in X_Y:\n",
        "        eY \u003d tf.expand_dims(eY,0)\n",
        "        eY_doms.append(x)\n",
        "    perm_eY \u003d []\n",
        "    for y in eY_doms:\n",
        "        perm_eY.append(eX_doms.index(y))\n",
        "    eY \u003d tf.transpose(eY,perm_eY + [len(perm_eY)])\n",
        "    mult_eX \u003d [1]*(len(eX_doms)+1)\n",
        "    mult_eY \u003d [1]*(len(eY_doms)+1)\n",
        "    for i in range(len(mult_eX)-1):\n",
        "        mult_eX[i] \u003d tf.maximum(1,tf.floor_div(tf.shape(eY)[i],tf.shape(eX)[i]))\n",
        "        mult_eY[i] \u003d tf.maximum(1,tf.floor_div(tf.shape(eX)[i],tf.shape(eY)[i]))\n",
        "    result1 \u003d tf.tile(eX,mult_eX)\n",
        "    result2 \u003d tf.tile(eY,mult_eY)\n",
        "    result \u003d tf.concat([result1,result2],axis\u003d-1)\n",
        "    result1.doms \u003d eX_doms\n",
        "    result2.doms \u003d eX_doms\n",
        "    result.doms \u003d eX_doms\n",
        "    return result,[result1,result2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "\u0027function\u0027 object is not iterable",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m\u003cipython-input-11-5108e614b3a1\u003e\u001b[0m in \u001b[0;36m\u003cmodule\u003e\u001b[1;34m\u001b[0m\n\u001b[1;32m----\u003e 1\u001b[1;33m \u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mresult1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mresult2\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m\u003d\u001b[0m \u001b[0mcross_2args\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;31mTypeError\u001b[0m: \u0027function\u0027 object is not iterable"
          ]
        }
      ],
      "source": [
        "result, [result1,result2] \u003d cross_2args"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\u003ctf.Tensor \u0027a_2:0\u0027 shape\u003d(1,) dtype\u003dfloat32\u003e"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ltn.And(a)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "\u0027NoneType\u0027 object is not callable",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m\u003cipython-input-13-0638c176d9ba\u003e\u001b[0m in \u001b[0;36m\u003cmodule\u003e\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0msess\u001b[0m \u001b[1;33m\u003d\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mdata_in\u001b[0m \u001b[1;33m\u003d\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m\u003d\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----\u003e 4\u001b[1;33m \u001b[0ml\u001b[0m \u001b[1;33m\u003d\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mOr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m\u003d\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mc_data\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;32m\u003cipython-input-8-bfa667276270\u003e\u001b[0m in \u001b[0;36mOr\u001b[1;34m(*wffs)\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mcross_wffs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0m_\u001b[0m \u001b[1;33m\u003d\u001b[0m \u001b[0mcross_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwffs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0mlabel\u001b[0m \u001b[1;33m\u003d\u001b[0m \u001b[1;34m\"_OR_\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mwff\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\":\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mwff\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mwffs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----\u003e 8\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m\u003d\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0midentity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF_Or\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcross_wffs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m\u003d\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m         \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdoms\u001b[0m \u001b[1;33m\u003d\u001b[0m \u001b[0mcross_wffs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdoms\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mTypeError\u001b[0m: \u0027NoneType\u0027 object is not callable"
          ]
        }
      ],
      "source": [
        "c \u003d tf.placeholder(tf.float32)\n",
        "sess \u003d tf.Session()\n",
        "data_in \u003d np.stack(data, axis\u003d1)\n",
        "l \u003d sess.run(Or(c), feed_dict\u003d{c:c_data})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "\u0027NoneType\u0027 object is not callable",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m\u003cipython-input-14-be900875da37\u003e\u001b[0m in \u001b[0;36m\u003cmodule\u003e\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----\u003e 2\u001b[1;33m     \u001b[0mc\u001b[0m \u001b[1;33m\u003d\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mAnd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mdata_c\u001b[0m \u001b[1;33m\u003d\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mltn_draw_logicals\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m\u003d\u001b[0m\u001b[0mdata_a\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m\u003d\u001b[0m\u001b[0mdata_b\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m\u003d\u001b[0m\u001b[0mdata_c\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[1;33m\u003d\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m\u003d\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m\u003cipython-input-8-bfa667276270\u003e\u001b[0m in \u001b[0;36mAnd\u001b[1;34m(*wffs)\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[0mcross_wffs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0m_\u001b[0m \u001b[1;33m\u003d\u001b[0m \u001b[0mcross_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwffs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[0mlabel\u001b[0m \u001b[1;33m\u003d\u001b[0m \u001b[1;34m\"_AND_\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mwff\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\":\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mwff\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mwffs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---\u003e 20\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m\u003d\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0midentity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF_And\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcross_wffs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m\u003d\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m         \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdoms\u001b[0m \u001b[1;33m\u003d\u001b[0m \u001b[0mcross_wffs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdoms\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mTypeError\u001b[0m: \u0027NoneType\u0027 object is not callable"
          ]
        }
      ],
      "source": [
        "with tf.Session() as sess:\n",
        "    c \u003d sess.run(And(a)); \n",
        "    data_c \u003d np.array(c)\n",
        "    utils.ltn_draw_logicals(a\u003ddata_a, b\u003ddata_b, c\u003ddata_c, title\u003dop, labels\u003dlabels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}