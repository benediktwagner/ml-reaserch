{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# About Logic Tensor Network (LTN)\n",
    "This notebook decomposes and investigates an LTN library in order to understand its building blocks.<br>\n",
    "This is work in progress.\n",
    "\n",
    "This video explains the tutorials https://www.youtube.com/watch?v=KhkCjCmK8m0 (in second half)<br>\n",
    "`Rights to be wrong reserved`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "LTN imported from:  C:\\Users\\Greg\\Documents\\Projects\\LTN\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "# path to LTN to include in system paths\n",
    "path = 'C:\\\\Users\\\\Greg\\\\Documents\\\\Projects\\\\LTN'\n",
    "sys.path.append(path)\n",
    "\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import logictensornetworks as ltn\n",
    "import numpy as np\n",
    "import utils_ltn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "print('LTN imported from: ', os.path.dirname(ltn.__file__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "LAYERS = 4\n",
    "BIAS_factor = 0.0\n",
    "BIAS = 0.0\n",
    "\n",
    "# Global placeholders for logical symbols\n",
    "F_And = None\n",
    "F_Or = None\n",
    "F_Implies = None\n",
    "F_Equiv = None\n",
    "F_Not = None\n",
    "F_Forall = None\n",
    "F_Exists = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Norms\n",
    "This is a hyper-parametr that defines how logical operators are calculated, with the following options:\n",
    "- min\n",
    "- Lukasiewicz\n",
    "- product\n",
    "- mean\n",
    "\n",
    "wff, wffs = \"well formated formula/s\". Formulas are build using groundings in Real vectors.<br> \n",
    "(examples to add).\n",
    "The norms are used in Fuzzy Sets Theory.<br>\n",
    "Some videos and readings on this matters:\n",
    "- https://www.youtube.com/watch?v=oWqXwCEfY78\n",
    "- https://www.youtube.com/watch?v=a2i-lHS-c_I\n",
    "- ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from the ltn library\n",
    "def set_tnorm(tnorm):\n",
    "    assert tnorm in ['min','luk','prod','mean','']\n",
    "    global F_And,F_Or,F_Implies,F_Not,F_Equiv,F_Forall\n",
    "    if tnorm == \"min\":\n",
    "        def F_And(wffs):\n",
    "            return tf.reduce_min(wffs,axis=-1,keepdims=True)\n",
    "\n",
    "        def F_Or(wffs):\n",
    "            return tf.reduce_max(wffs,axis=-1,keepdims=True)\n",
    "\n",
    "        def F_Implies(wff1, wff2):\n",
    "            return tf.maximum(tf.to_float(tf.less_equal(wff1,wff2)),wff2)\n",
    "\n",
    "        def F_Not(wff):\n",
    "            return 1 - wff\n",
    "\n",
    "        def F_Equiv(wff1,wff2):\n",
    "            return tf.maximum(tf.to_float(tf.equal(wff1,wff2)),tf.minimum(wff1,wff2))\n",
    "\n",
    "    if tnorm == \"prod\":\n",
    "        def F_And(wffs):\n",
    "            return tf.reduce_prod(wffs,axis=-1,keepdims=True)\n",
    "\n",
    "        def F_Or(wffs):\n",
    "            return 1-tf.reduce_prod(1-wffs,axis=-1,keepdims=True)\n",
    "\n",
    "        def F_Implies(wff1, wff2):\n",
    "            le_wff1_wff2 = tf.to_float(tf.less_equal(wff1,wff2))\n",
    "            gt_wff1_wff2 = tf.to_float(tf.greater(wff1,wff2))\n",
    "            return tf.cond(tf.equal(wff1[0],0),lambda:le_wff1_wff2 + gt_wff1_wff2*wff2/wff1,lambda:tf.constant([1.0]))\n",
    "\n",
    "        def F_Not(wff):\n",
    "            # according to standard goedel logic is\n",
    "            # return tf.to_float(tf.equal(wff,1))\n",
    "            return 1-wff\n",
    "\n",
    "        def F_Equiv(wff1,wff2):\n",
    "            return tf.minimum(wff1/wff2,wff2/wff1)\n",
    "\n",
    "    if tnorm == \"mean\":\n",
    "        def F_And(wffs):\n",
    "            return tf.reduce_mean(wffs,axis=-1,keepdims=True)\n",
    "\n",
    "        def F_Or(wffs):\n",
    "            return tf.reduce_max(wffs,axis=-1,keepdims=True)\n",
    "\n",
    "        def F_Implies(wff1, wff2):\n",
    "            return tf.clip_by_value(2*wff2-wff1,0,1)\n",
    "\n",
    "        def F_Not(wff):\n",
    "            return 1 - wff\n",
    "\n",
    "        def F_Equiv(wff1,wff2):\n",
    "            return 1 - tf.abs(wff1-wff2)\n",
    "\n",
    "    if tnorm == \"luk\":\n",
    "        def F_And(wffs):\n",
    "            return tf.maximum(0.0,tf.reduce_sum(wffs,axis=-1,keepdims=True)+1-tf.to_float(tf.shape(wffs)[-1]))\n",
    "\n",
    "        def F_Or(wffs):\n",
    "            return tf.minimum(tf.reduce_sum(wffs,axis=-1,keepdims=True),1.0,)\n",
    "\n",
    "        def F_Implies(wff1, wff2):\n",
    "            return tf.minimum(1.,1 - wff1 + wff2)\n",
    "\n",
    "        def F_Not(wff):\n",
    "            return 1 - wff\n",
    "\n",
    "        def F_Equiv(wff1,wff2):\n",
    "            return 1 - tf.abs(wff1-wff2)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `draw_ltn_operators` in `utils_ltn.py` has been created to visualise either unary or binary operators.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.5 0.1]\n",
      " [0.2 0.3]\n",
      " [0.6 0.2]\n",
      " [0.2 0.4]\n",
      " [0.3 0.6]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set a desired norm\n",
    "ltn.set_tnorm(\"min\")\n",
    "\n",
    "# some data \n",
    "data = np.array([[0.5, 0.2, 0.6, 0.2, 0.3], \n",
    "                 [0.1, 0.3, 0.2, 0.4, 0.6]], dtype=np.float32)\n",
    "\n",
    "labels = ['d_'+str(i+1) for i in np.arange(len(data[0]))]\n",
    "\n",
    "formulas = tf.placeholder(dtype=tf.float32)\n",
    "\n",
    "\n",
    "data_a, data_b = data[0], data[1] \n",
    "\n",
    "a = ltn.variable('a', data_a)\n",
    "b = ltn.variable('a', data_b)\n",
    "\n",
    "op = ltn.F_Or\n",
    "if op == ltn.F_And or op == ltn.F_Or:\n",
    "    with tf.Session() as sess:\n",
    "        data_in = np.stack(data, axis=1)\n",
    "        c = sess.run(op(formulas), feed_dict={formulas: data_in}) \n",
    "        data_c = np.array(utils_ltn.flat_list(c))\n",
    "        print(data_in)\n",
    "        utils_ltn.draw_ltn_operators(a=data_a, b=data_b, c=data_c, title=op, labels=labels)\n",
    "\n",
    "elif op == ltn.F_Implies or op == ltn.F_Equiv:\n",
    "    with tf.Session() as sess:\n",
    "        c = sess.run(op(a, b), feed_dict={a:data_a, b:data_b})\n",
    "        data_c = np.array(c)\n",
    "        utils_ltn.draw_ltn_operators(a=data_a, b=data_b, c=data_c, title=op, labels=labels)\n",
    "    \n",
    "elif op == ltn.F_Not:\n",
    "    with tf.Session() as sess:\n",
    "        c = sess.run(op(a), feed_dict={a:data_a})\n",
    "        data_c = np.array(c)\n",
    "        utils_ltn.draw_ltn_operators(a=data_a, c=data_c, title=op, labels=labels)\n",
    "else: 'Not implemented'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_universal_aggreg(aggreg):\n",
    "    assert aggreg in ['hmean','min','mean']\n",
    "    global F_Forall\n",
    "    if aggreg == \"hmean\":\n",
    "        def F_Forall(axis,wff):\n",
    "            return 1/tf.reduce_mean(1/(wff+1e-10),axis=axis)\n",
    "\n",
    "    if aggreg == \"min\":\n",
    "        def F_Forall(axis,wff):\n",
    "            return tf.reduce_min(wff,axis=axis)\n",
    "\n",
    "    if aggreg == \"mean\":\n",
    "        def F_Forall(axis,wff):\n",
    "            return tf.reduce_mean(wff, axis=axis)\n",
    "\n",
    "\n",
    "def set_existential_aggregator(aggreg):\n",
    "    assert  aggreg in ['max']\n",
    "    global F_Exists\n",
    "    if aggreg == \"max\":\n",
    "        def F_Exists(axis, wff):\n",
    "            return tf.reduce_max(wff, axis=axis)\n",
    "        \n",
    "set_universal_aggreg(\"hmean\")\n",
    "set_existential_aggregator(\"max\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function logictensornetworks.Or>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ltn.Or()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "............"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To be continued piece by piece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Or(*wffs):\n",
    "    if len(wffs) == 0:\n",
    "        result = tf.constant(0.0)\n",
    "        result.doms = []\n",
    "    else:\n",
    "        cross_wffs,_ = cross_args(wffs)\n",
    "        label = \"_OR_\".join([wff.name.split(\":\")[0] for wff in wffs])\n",
    "        result = tf.identity(F_Or(cross_wffs),name=label)\n",
    "        result.doms = cross_wffs.doms\n",
    "    return result\n",
    "\n",
    "\n",
    "def And(*wffs):\n",
    "    if len(wffs) == 0:\n",
    "        result = tf.constant(1.0)\n",
    "        result.doms = []\n",
    "    else:\n",
    "        cross_wffs,_ = cross_args(wffs)\n",
    "        label = \"_AND_\".join([wff.name.split(\":\")[0] for wff in wffs])\n",
    "        result = tf.identity(F_And(cross_wffs),name=label)\n",
    "        result.doms = cross_wffs.doms\n",
    "    return result\n",
    "\n",
    "\n",
    "#def Or(*wffs):\n",
    "#    if len(wffs) == 0:\n",
    " #       result = tf.constant(0.0)\n",
    "#        result.doms = []\n",
    "#    else:\n",
    "#        cross_wffs,_ = cross_args(wffs)\n",
    " #       label = \"_OR_\".join([wff.name.split(\":\")[0] for wff in wffs])\n",
    "  #      result = tf.identity(F_Or(cross_wffs),name=label)\n",
    " #       result.doms = cross_wffs.doms\n",
    "#    return result\n",
    "\n",
    "\n",
    "def Implies(wff1, wff2):\n",
    "    _, cross_wffs = cross_2args(wff1,wff2)\n",
    "    label = wff1.name.split(\":\")[0] + \"_IMP_\" + wff2.name.split(\":\")[0]\n",
    "    result = F_Implies(cross_wffs[0],cross_wffs[1])\n",
    "    result = tf.identity(result,name=label)\n",
    "    result.doms = cross_wffs[0].doms\n",
    "    return result\n",
    "\n",
    "def Not(wff):\n",
    "    result = F_Not(wff)\n",
    "    label = \"NOT_\" + wff.name.split(\":\")[0]\n",
    "    result = tf.identity(result,name=label)\n",
    "    result.doms = wff.doms\n",
    "    return result\n",
    "\n",
    "def Equiv(wff1,wff2):\n",
    "    _, cross_wffs = cross_2args(wff1,wff2)\n",
    "    label = wff1.name.split(\":\")[0] + \"_IFF_\" + wff2.name.split(\":\")[0]\n",
    "    result = F_Equiv(cross_wffs[0],cross_wffs[1])\n",
    "    result.doms = cross_wffs[0].doms\n",
    "    return result\n",
    "\n",
    "def Forall(vars,wff):\n",
    "    if type(vars) is not tuple:\n",
    "        vars = (vars,)\n",
    "    result_doms = [x for x in wff.doms if x not in [var.doms[0] for var in vars]]\n",
    "    quantif_axis = [wff.doms.index(var.doms[0]) for var in vars]\n",
    "    not_empty_vars = tf.cast(tf.reduce_prod(tf.stack([tf.size(var) for var in vars])),tf.bool)\n",
    "    ones = tf.ones((1,)*(len(result_doms)+1))\n",
    "    result = tf.cond(not_empty_vars,lambda:F_Forall(quantif_axis,wff),lambda:ones)\n",
    "    result.doms = result_doms\n",
    "    return result\n",
    "\n",
    "def Exists(vars,wff):\n",
    "    if type(vars) is not tuple:\n",
    "        vars = (vars,)\n",
    "    result_doms = [x for x in wff.doms if x not in [var.doms[0] for var in vars]]\n",
    "    quantif_axis = [wff.doms.index(var.doms[0]) for var in vars]\n",
    "    not_empty_vars = tf.cast(tf.reduce_prod(tf.stack([tf.size(var) for var in vars])),tf.bool)\n",
    "    zeros = tf.zeros((1,)*(len(result_doms)+1))\n",
    "    result = tf.cond(not_empty_vars,lambda:F_Exists(quantif_axis,wff),lambda:zeros)\n",
    "    result.doms = result_doms\n",
    "    return result\n",
    "\n",
    "# tf.cast\n",
    "# tf.stack VS np.stack\n",
    "# tf.size\n",
    "\n",
    "\n",
    "def variable(label,number_of_features_or_feed):\n",
    "    if type(number_of_features_or_feed) is int:\n",
    "        result = tf.placeholder(dtype=tf.float32,shape=(None,number_of_features_or_feed),name=label)\n",
    "    elif isinstance(number_of_features_or_feed,tf.Tensor):\n",
    "        result = tf.identity(number_of_features_or_feed,name=label)\n",
    "    else:\n",
    "        result = tf.constant(number_of_features_or_feed,name=label)\n",
    "    result.doms = [label]\n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def constant(label,value=None,\n",
    "                 min_value=None,\n",
    "                 max_value=None):\n",
    "    label = \"ltn_constant_\"+label\n",
    "    if value is not None:\n",
    "        result = tf.constant(value,name=label)\n",
    "    else:\n",
    "        result = tf.Variable(tf.random_uniform(\n",
    "                shape=(1,len(min_value)),\n",
    "                minval=min_value,\n",
    "                maxval=max_value,name=label))\n",
    "    result.doms = []\n",
    "    return result\n",
    "\n",
    "def function(label, input_shape_spec, output_shape_spec=1,fun_definition=None):\n",
    "    if type(input_shape_spec) is list:\n",
    "        number_of_features = sum([int(v.shape[1]) for v in input_shape_spec])\n",
    "    elif type(input_shape_spec) is tf.Tensor:\n",
    "        number_of_features = int(input_shape_spec.shape[1])\n",
    "    else:\n",
    "        number_of_features = input_shape_spec\n",
    "    if fun_definition is None:\n",
    "        W = tf.Variable(\n",
    "                tf.random_normal(\n",
    "                    [number_of_features + 1,output_shape_spec],mean=0,stddev=1), name=\"W\" + label)\n",
    "        def apply_fun(*args):\n",
    "            tensor_args = tf.concat(args,axis=1)\n",
    "            X = tf.concat([tf.ones((tf.shape(tensor_args)[0], 1)),\n",
    "                           tensor_args], 1)\n",
    "            result = tf.matmul(X,W)\n",
    "            return result\n",
    "        pars = [W]\n",
    "    else:\n",
    "        def apply_fun(*args):\n",
    "            return fun_definition(*args)\n",
    "        pars = []\n",
    "\n",
    "    def fun(*args):\n",
    "        crossed_args, list_of_args_in_crossed_args = cross_args(args)\n",
    "        result = apply_fun(*list_of_args_in_crossed_args)\n",
    "        if crossed_args.doms != []:\n",
    "            result = tf.reshape(result, tf.concat([tf.shape(crossed_args)[:-1],\n",
    "                                                   tf.shape(result)[-1:]],axis=0))\n",
    "        else:\n",
    "            result = tf.reshape(result, (output_shape_spec,))\n",
    "        result.doms = crossed_args.doms\n",
    "        return result\n",
    "    fun.pars = pars\n",
    "    fun.label=label\n",
    "    return fun\n",
    "\n",
    "def proposition(label,initial_value=None,value=None):\n",
    "    if value is not None:\n",
    "        assert 0 <= value and value <= 1\n",
    "        result = tf.constant([value])\n",
    "    elif initial_value is not None:\n",
    "        assert 0 <= initial_value <= 1\n",
    "        result = tf.Variable(initial_value=[value])\n",
    "    else:\n",
    "        result = tf.expand_dims(tf.clip_by_value(tf.Variable(tf.random_normal(shape=(),mean=.5,stddev=.5)),0.,1.),dim=0)\n",
    "    result.doms = ()\n",
    "    return result\n",
    "\n",
    "def predicate(label,number_of_features_or_vars,pred_definition=None):\n",
    "    global BIAS\n",
    "    if type(number_of_features_or_vars) is list:\n",
    "        number_of_features = sum([int(v.shape[1]) for v in number_of_features_or_vars])\n",
    "    elif type(number_of_features_or_vars) is tf.Tensor:\n",
    "        number_of_features = int(number_of_features_or_vars.shape[1])\n",
    "    else:\n",
    "        number_of_features = number_of_features_or_vars\n",
    "    if pred_definition is None:\n",
    "        W = tf.matrix_band_part(\n",
    "            tf.Variable(\n",
    "                tf.random_normal(\n",
    "                    [LAYERS,\n",
    "                     number_of_features + 1,\n",
    "                     number_of_features + 1],mean=0,stddev=1), name=\"W\" + label), 0, -1)\n",
    "        u = tf.Variable(tf.ones([LAYERS, 1]),\n",
    "                        name=\"u\" + label)\n",
    "        def apply_pred(*args):\n",
    "            app_label = label + \"/\" + \"_\".join([arg.name.split(\":\")[0] for arg in args]) + \"/\"\n",
    "            tensor_args = tf.concat(args,axis=1)\n",
    "            X = tf.concat([tf.ones((tf.shape(tensor_args)[0], 1)),\n",
    "                           tensor_args], 1)\n",
    "            XW = tf.matmul(tf.tile(tf.expand_dims(X, 0), [LAYERS, 1, 1]), W)\n",
    "            XWX = tf.squeeze(tf.matmul(tf.expand_dims(X, 1), tf.transpose(XW, [1, 2, 0])), axis=[1])\n",
    "            gX = tf.matmul(tf.tanh(XWX), u)\n",
    "            result = tf.sigmoid(gX, name=app_label)\n",
    "            return result\n",
    "        pars = [W,u]\n",
    "    else:\n",
    "        def apply_pred(*args):\n",
    "            return pred_definition(*args)\n",
    "        pars = []\n",
    "\n",
    "    def pred(*args):\n",
    "        global BIAS\n",
    "        crossed_args, list_of_args_in_crossed_args = cross_args(args)\n",
    "        result = apply_pred(*list_of_args_in_crossed_args)\n",
    "        if crossed_args.doms != []:\n",
    "            result = tf.reshape(result, tf.concat([tf.shape(crossed_args)[:-1],[1]],axis=0))\n",
    "        else:\n",
    "            result = tf.reshape(result, (1,))\n",
    "        result.doms = crossed_args.doms\n",
    "        BIAS = tf.divide(BIAS + .5 - tf.reduce_mean(result),2)*BIAS_factor\n",
    "        return result\n",
    "    pred.pars = pars\n",
    "    pred.label=label\n",
    "    return pred\n",
    "\n",
    "def cross_args(args):\n",
    "    result = args[0]\n",
    "    for arg in args[1:]:\n",
    "        result,_ = cross_2args(result,arg)\n",
    "    result_flat = tf.reshape(result,\n",
    "                             (tf.reduce_prod(tf.shape(result)[:-1]),\n",
    "                              tf.shape(result)[-1]))\n",
    "    result_args = tf.split(result_flat,[tf.shape(arg)[-1] for arg in args],1)\n",
    "    return result, result_args\n",
    "\n",
    "def cross_2args(X,Y):\n",
    "    if X.doms == [] and Y.doms == []:\n",
    "        result = tf.concat([X,Y],axis=-1)\n",
    "        result.doms = []\n",
    "        return result,[X,Y]\n",
    "    X_Y = set(X.doms) - set(Y.doms)\n",
    "    Y_X = set(Y.doms) - set(X.doms)\n",
    "    eX = X\n",
    "    eX_doms = [x for x in X.doms]\n",
    "    for y in Y_X:\n",
    "        eX = tf.expand_dims(eX,0)\n",
    "        eX_doms.append(y)\n",
    "    eY = Y\n",
    "    eY_doms = [y for y in Y.doms]\n",
    "    for x in X_Y:\n",
    "        eY = tf.expand_dims(eY,0)\n",
    "        eY_doms.append(x)\n",
    "    perm_eY = []\n",
    "    for y in eY_doms:\n",
    "        perm_eY.append(eX_doms.index(y))\n",
    "    eY = tf.transpose(eY,perm_eY + [len(perm_eY)])\n",
    "    mult_eX = [1]*(len(eX_doms)+1)\n",
    "    mult_eY = [1]*(len(eY_doms)+1)\n",
    "    for i in range(len(mult_eX)-1):\n",
    "        mult_eX[i] = tf.maximum(1,tf.floor_div(tf.shape(eY)[i],tf.shape(eX)[i]))\n",
    "        mult_eY[i] = tf.maximum(1,tf.floor_div(tf.shape(eX)[i],tf.shape(eY)[i]))\n",
    "    result1 = tf.tile(eX,mult_eX)\n",
    "    result2 = tf.tile(eY,mult_eY)\n",
    "    result = tf.concat([result1,result2],axis=-1)\n",
    "    result1.doms = eX_doms\n",
    "    result2.doms = eX_doms\n",
    "    result.doms = eX_doms\n",
    "    return result,[result1,result2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_2args(X,Y):\n",
    "    if X.doms == [] and Y.doms == []:\n",
    "        result = tf.concat([X,Y],axis=-1)\n",
    "        result.doms = []\n",
    "        return result,[X,Y]\n",
    "    X_Y = set(X.doms) - set(Y.doms)\n",
    "    Y_X = set(Y.doms) - set(X.doms)\n",
    "    eX = X\n",
    "    eX_doms = [x for x in X.doms]\n",
    "    for y in Y_X:\n",
    "        eX = tf.expand_dims(eX,0)\n",
    "        eX_doms.append(y)\n",
    "    eY = Y\n",
    "    eY_doms = [y for y in Y.doms]\n",
    "    for x in X_Y:\n",
    "        eY = tf.expand_dims(eY,0)\n",
    "        eY_doms.append(x)\n",
    "    perm_eY = []\n",
    "    for y in eY_doms:\n",
    "        perm_eY.append(eX_doms.index(y))\n",
    "    eY = tf.transpose(eY,perm_eY + [len(perm_eY)])\n",
    "    mult_eX = [1]*(len(eX_doms)+1)\n",
    "    mult_eY = [1]*(len(eY_doms)+1)\n",
    "    for i in range(len(mult_eX)-1):\n",
    "        mult_eX[i] = tf.maximum(1,tf.floor_div(tf.shape(eY)[i],tf.shape(eX)[i]))\n",
    "        mult_eY[i] = tf.maximum(1,tf.floor_div(tf.shape(eX)[i],tf.shape(eY)[i]))\n",
    "    result1 = tf.tile(eX,mult_eX)\n",
    "    result2 = tf.tile(eY,mult_eY)\n",
    "    result = tf.concat([result1,result2],axis=-1)\n",
    "    result1.doms = eX_doms\n",
    "    result2.doms = eX_doms\n",
    "    result.doms = eX_doms\n",
    "    return result,[result1,result2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result, [result1,result2] = cross_2args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'a_6_2:0' shape=<unknown> dtype=float32>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ltn.And(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Or' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-0638c176d9ba>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0msess\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mdata_in\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0ml\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mOr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mc_data\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'Or' is not defined"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "c = tf.placeholder(tf.float32)\n",
    "sess = tf.Session()\n",
    "data_in = np.stack(data, axis=1)\n",
    "l = sess.run(Or(c), feed_dict={c:c_data})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'And' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-be900875da37>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mAnd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mdata_c\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mltn_draw_logicals\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata_a\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata_b\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata_c\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'And' is not defined"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    c = sess.run(And(a)); \n",
    "    data_c = np.array(c)\n",
    "    utils.ltn_draw_logicals(a=data_a, b=data_b, c=data_c, title=op, labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
